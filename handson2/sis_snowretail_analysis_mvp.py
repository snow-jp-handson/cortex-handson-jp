# =========================================================
# Snowflake Cortex AI ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—
# é¡§å®¢ã®å£°åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - MVP
# =========================================================
# æ¦‚è¦: 
# ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€Snowflake Cortex AIã¨Streamlitã‚’ä½¿ç”¨ã—ã¦ã€
# é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åˆ†æã¨ç¤¾å†…æ–‡æ›¸ã®æ¤œç´¢ã‚’è¡Œã†ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚
#
# æ©Ÿèƒ½:
# - é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ„Ÿæƒ…åˆ†æã¨å¯è¦–åŒ–
# - ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¤œç´¢
# - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
# - Cortex Searchã‚’ç”¨ã„ãŸRAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã‚ˆã‚‹ç¤¾å†…æ–‡æ›¸Q&A
# - Cortex Analystã«ã‚ˆã‚‹è‡ªç„¶è¨€èªåˆ†æ
#
# Created by Tsubasa Kanno @Snowflake
# æœ€çµ‚æ›´æ–°: 2025/03/29
# =========================================================

# =========================================================
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# =========================================================
# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import streamlit as st
import pandas as pd
import json
import time
import requests

# Streamlitã®è¨­å®š
st.set_page_config(layout="wide")

# å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import plotly.express as px

# Snowflakeé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from snowflake.snowpark.context import get_active_session
from snowflake.cortex import Complete as CompleteText
from snowflake.core import Root

# =========================================================
# å®šæ•°å®šç¾©
# =========================================================
# Cortex Analyst APIã®è¨­å®š
ANALYST_API_ENDPOINT = "/api/v2/cortex/analyst/message"
ANALYST_API_TIMEOUT = 50  # ç§’

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«é¸æŠè‚¢
EMBEDDING_MODELS = [
    "multilingual-e5-large",
    "voyage-multilingual-2",
    "snowflake-arctic-embed-l-v2.0",
    "nv-embed-qa-4"
]

# COMPLETEé–¢æ•°ç”¨ã®LLMãƒ¢ãƒ‡ãƒ«é¸æŠè‚¢
COMPLETE_MODELS = [
    "claude-3-5-sonnet",
    "deepseek-r1",
    "mistral-large2",
    "llama3.3-70b",
    "snowflake-llama-3.3-70b"
]

# Cortex Search Serviceç”¨ã®ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«é¸æŠè‚¢
SEARCH_MODELS = [
    "voyage-multilingual-2",
    "snowflake-arctic-embed-m-v1.5",
    "snowflake-arctic-embed-l-v2.0"
]

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒª
DEFAULT_CATEGORIES = [
    "å•†å“ã®å“è³ª",
    "ä¾¡æ ¼",
    "æ¥å®¢ã‚µãƒ¼ãƒ“ã‚¹",
    "åº—èˆ—ç’°å¢ƒ",
    "é…é€ãƒ»æ¢±åŒ…",
    "å“æƒãˆ",
    "ä½¿ã„ã‚„ã™ã•",
    "é®®åº¦",
    "ãã®ä»–"
]

# =========================================================
# Snowflakeæ¥ç¶šã¨å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================================================

# Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—
snowflake_session = get_active_session()

def check_table_exists(table_name: str) -> bool:
    """æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    
    Args:
        table_name (str): ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«å
    
    Returns:
        bool: ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯Trueã€å­˜åœ¨ã—ãªã„å ´åˆã¯False
    """
    try:
        snowflake_session.sql(f"DESC {table_name}").collect()
        return True
    except:
        return False

def get_table_count(table_name: str) -> int:
    """æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Args:
        table_name (str): ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«å
    
    Returns:
        int: ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯0ï¼‰
    """
    try:
        result = snowflake_session.sql(f"""
            SELECT COUNT(*) as count FROM {table_name}
        """).collect()
        return result[0]['COUNT']
    except:
        return 0

def get_available_warehouses() -> list:
    """åˆ©ç”¨å¯èƒ½ãªSnowflakeã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹ã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Returns:
        list: ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹åã®ãƒªã‚¹ãƒˆï¼ˆå–å¾—å¤±æ•—æ™‚ã¯ç©ºãƒªã‚¹ãƒˆï¼‰
    """
    try:
        result = snowflake_session.sql("SHOW WAREHOUSES").collect()
        return [row['name'] for row in result]
    except Exception as e:
        st.error(f"ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

# =========================================================
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°
# =========================================================

# =========================================================
# ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–ãƒ»æº–å‚™
# =========================================================

def create_customer_analysis_table() -> bool:
    """
    é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚
    
    CUSTOMER_ANALYSISãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã€
    ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã€æ„Ÿæƒ…åˆ†æã®çµæœã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    ãƒ†ãƒ¼ãƒ–ãƒ«ã¯æ—¢å­˜ã®å ´åˆã¯å†ä½œæˆã›ãšã€å­˜åœ¨ã—ãªã„å ´åˆã®ã¿ä½œæˆã—ã¾ã™ï¼ˆCREATE IF NOT EXISTSï¼‰ã€‚
    
    ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :
    - analysis_id: è‡ªå‹•æ¡ç•ªã®ID
    - review_id: å…ƒãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å‚ç…§ID
    - product_id: è£½å“ID
    - customer_id: é¡§å®¢ID
    - rating: è©•ä¾¡ï¼ˆæ˜Ÿã®æ•°ï¼‰
    - review_text: å…ƒã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆå…¨æ–‡
    - review_date: ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥æ™‚
    - purchase_channel: è³¼å…¥ãƒãƒ£ãƒãƒ«
    - helpful_votes: å‚è€ƒã«ãªã£ãŸæŠ•ç¥¨æ•°
    - chunked_text: ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡
    - embedding: ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ã®ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ (VECTORå‹)
    - sentiment_score: æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ (-1ã€œ1ã®ç¯„å›²)
    - updated_at: æœ€çµ‚æ›´æ–°æ—¥æ™‚
    
    Returns:
        bool: ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        st.info("é¡§å®¢åˆ†æãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
        snowflake_session.sql("""
        CREATE TABLE IF NOT EXISTS CUSTOMER_ANALYSIS (
            analysis_id NUMBER AUTOINCREMENT,
            review_id VARCHAR(20),
            product_id VARCHAR(10),
            customer_id VARCHAR(10),
            rating NUMBER(2,1),
            review_text TEXT,
            review_date TIMESTAMP_NTZ,
            purchase_channel VARCHAR(20),
            helpful_votes NUMBER(5),
            chunked_text TEXT,
            embedding VECTOR(FLOAT, 1024),
            sentiment_score FLOAT,
            updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
        )
        """).collect()
        
        st.success("é¡§å®¢åˆ†æãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å†…å®¹ã‚’ç¢ºèª
        count = get_table_count("CUSTOMER_ANALYSIS")
        if count > 0:
            st.info(f"æ—¢å­˜ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒ {count} ä»¶ã‚ã‚Šã¾ã™")
        
        return True
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def process_review_chunks() -> bool:
    """
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    
    ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’é †ç•ªã«è¡Œã„ã¾ã™ï¼š
    1. RETAIL_DATA_WITH_PRODUCT_MASTERã¨EC_DATA_WITH_PRODUCT_MASTERã‹ã‚‰æœªå‡¦ç†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    2. CUSTOMER_REVIEWSãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã¨é–¢é€£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    3. ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    4. ãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨ä½“ã‚’è‹±èªã«ç¿»è¨³ã—ã¦æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ
    5. å„ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆEMBED_TEXT_1024ã‚’ä½¿ç”¨ï¼‰
    6. ã™ã¹ã¦ã®çµæœã‚’CUSTOMER_ANALYSISãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    
    ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã«ã¯ã€SPLIT_TEXT_RECURSIVE_CHARACTERé–¢æ•°ã‚’ä½¿ç”¨ã—ã€
    æœ€å¤§300æ–‡å­—ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã§ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã¾ã™ã€‚
    
    æ„Ÿæƒ…åˆ†æã¯ã€SENTIMENTé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦-1ï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã€œ1ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®
    ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™ã€‚æ—¥æœ¬èªã‚’æ­£ç¢ºã«åˆ†æã™ã‚‹ãŸã‚ã«ã€ã¾ãšSNOWFLAKE.CORTEX.TRANSLATE
    é–¢æ•°ã§è‹±èªã«ç¿»è¨³ã—ã¦ã‹ã‚‰æ„Ÿæƒ…åˆ†æã‚’è¡Œã„ã¾ã™ã€‚æ„Ÿæƒ…åˆ†æã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨ä½“ã§è¡Œã„ã€
    åŒä¸€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã«åŒã˜ã‚¹ã‚³ã‚¢ã‚’é©ç”¨ã—ã¾ã™ã€‚
    
    ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¯EMBED_TEXT_1024é–¢æ•°ã‚’ä½¿ç”¨ã—ã€é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§
    ãƒ†ã‚­ã‚¹ãƒˆã‚’1024æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚
    
    Returns:
        bool: å‡¦ç†ã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: æœªå‡¦ç†ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
        # RETAIL_DATA_WITH_PRODUCT_MASTERã¨EC_DATA_WITH_PRODUCT_MASTERã‚’ä½¿ç”¨ã—ã¤ã¤
        # Review_IDã‚„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆãªã©ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã¯CUSTOMER_REVIEWSãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ã™ã‚‹
        reviews = snowflake_session.sql("""
            SELECT r.*
            FROM CUSTOMER_REVIEWS r
            LEFT JOIN CUSTOMER_ANALYSIS a
            ON r.review_id = a.review_id
            WHERE a.review_id IS NULL
            -- å…¨ä»¶å‡¦ç†ã™ã‚‹ãŸã‚ã«åˆ¶é™ã‚’å‰Šé™¤
        """).collect()
        
        if not reviews:
            st.info("å‡¦ç†ãŒå¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return True
        
        # é€²æ—ãƒãƒ¼ã¨ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã®åˆæœŸåŒ–
        st.write(f"**åˆè¨ˆ {len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å‡¦ç†ã—ã¾ã™**")
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        # å‡¦ç†æ¸ˆã¿ã®ç·ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¿½è·¡
        total_chunks_processed = 0
        
        for i, review in enumerate(reviews):
            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨ä½“ã®æ„Ÿæƒ…åˆ†æ
            # å…¨ä½“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã«ç¿»è¨³
            translated_full_text = snowflake_session.sql("""
                SELECT SNOWFLAKE.CORTEX.TRANSLATE(?, '', 'en') as translated
            """, params=[review['REVIEW_TEXT']]).collect()[0]['TRANSLATED']
            
            # ãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨ä½“ã®æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆè‹±è¨³ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
            sentiment_score = snowflake_session.sql("""
                SELECT SNOWFLAKE.CORTEX.SENTIMENT(?) as score
            """, params=[translated_full_text]).collect()[0]['SCORE']
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunks = snowflake_session.sql("""
                SELECT t.value as chunk
                FROM (
                    SELECT SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(
                        ?,
                        'none',  -- åŒºåˆ‡ã‚Šæ–¹æ³•ï¼ˆæ®µè½ã‚„æ–‡ãªã©ï¼‰
                        300,     -- æœ€å¤§ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰
                        30        -- ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®æ–‡å­—æ•°
                    ) as split_result
                ),
                LATERAL FLATTEN(input => split_result) t
            """, params=[review['REVIEW_TEXT']]).collect()
            
            # å„ãƒãƒ£ãƒ³ã‚¯ã«å¯¾ã™ã‚‹å‡¦ç†
            for chunk_idx, chunk in enumerate(chunks):
                # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦çµæœã‚’æŒ¿å…¥
                snowflake_session.sql("""
                    INSERT INTO CUSTOMER_ANALYSIS (
                        review_id,
                        product_id,
                        customer_id,
                        rating,
                        review_text,
                        review_date,
                        purchase_channel,
                        helpful_votes,
                        chunked_text,
                        embedding,
                        sentiment_score
                    )
                    SELECT 
                        ?,
                        ?,
                        ?,
                        ?,
                        ?,
                        ?,
                        ?,
                        ?,
                        ?,
                        SNOWFLAKE.CORTEX.EMBED_TEXT_1024(?, ?),
                        ?
                """, params=[
                    review['REVIEW_ID'],
                    review['PRODUCT_ID'],
                    review['CUSTOMER_ID'],
                    review['RATING'],
                    review['REVIEW_TEXT'],
                    review['REVIEW_DATE'],
                    review['PURCHASE_CHANNEL'],
                    review['HELPFUL_VOTES'],
                    chunk['CHUNK'],
                    embedding_model,
                    chunk['CHUNK'],
                    sentiment_score  # ãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨ä½“ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã‚’å„ãƒãƒ£ãƒ³ã‚¯ã«é©ç”¨
                ]).collect()
                
                total_chunks_processed += 1
            
            # é€²æ—çŠ¶æ³ã®æ›´æ–°
            progress = (i + 1) / len(reviews)
            progress_bar.progress(progress)
            progress_text.text(f"å‡¦ç†é€²æ—: {i + 1}/{len(reviews)} ä»¶å®Œäº† (åˆè¨ˆ {total_chunks_processed} ãƒãƒ£ãƒ³ã‚¯å‡¦ç†æ¸ˆã¿)")
        
        st.success(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰åˆè¨ˆ {total_chunks_processed} ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¾ã—ãŸã€‚")
        return True
    except Exception as e:
        st.error(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.code(str(e))  # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã«è¡¨ç¤º
        return False

# =========================================================
# ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«æ“ä½œ
# =========================================================

def create_review_management_tables() -> bool:
    """
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚
    
    ä»¥ä¸‹ã®3ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼š
    1. REVIEW_CATEGORIES: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒªã®ãƒã‚¹ã‚¿ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
    2. REVIEW_TAGS: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ä»˜ä¸ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚¿ã‚°ã®æƒ…å ±
    3. REVIEW_WORDS: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸé‡è¦å˜èªæƒ…å ±
    
    ãƒ†ãƒ¼ãƒ–ãƒ«ã¯å­˜åœ¨ã—ãªã„å ´åˆã®ã¿ä½œæˆã•ã‚Œï¼ˆCREATE IF NOT EXISTSï¼‰ã€
    åˆæœŸãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªãŒREVIEW_CATEGORIESã«ç™»éŒ²ã•ã‚Œã¾ã™ã€‚
    
    ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :
    REVIEW_CATEGORIES:
    - category_id: è‡ªå‹•æ¡ç•ªã®ã‚«ãƒ†ã‚´ãƒªID
    - category_name: ã‚«ãƒ†ã‚´ãƒªå
    - description: ã‚«ãƒ†ã‚´ãƒªã®èª¬æ˜
    - created_at: ä½œæˆæ—¥æ™‚
    - updated_at: æ›´æ–°æ—¥æ™‚

    REVIEW_TAGS:
    - tag_id: è‡ªå‹•æ¡ç•ªã®ã‚¿ã‚°ID
    - review_id: ãƒ¬ãƒ“ãƒ¥ãƒ¼IDï¼ˆRETAIL_DATA_WITH_PRODUCT_MASTERã¨EC_DATA_WITH_PRODUCT_MASTERã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸIDã‚’å‚ç…§ï¼‰
    - category_name: ã‚«ãƒ†ã‚´ãƒªå
    - confidence_score: åˆ†é¡ã®ç¢ºä¿¡åº¦ã‚¹ã‚³ã‚¢
    - created_at: ä½œæˆæ—¥æ™‚
    - updated_at: æ›´æ–°æ—¥æ™‚
    
    REVIEW_WORDS:
    - word_id: è‡ªå‹•æ¡ç•ªã®å˜èªID
    - review_id: ãƒ¬ãƒ“ãƒ¥ãƒ¼IDï¼ˆRETAIL_DATA_WITH_PRODUCT_MASTERã¨EC_DATA_WITH_PRODUCT_MASTERã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸIDã‚’å‚ç…§ï¼‰
    - word: æŠ½å‡ºã•ã‚ŒãŸå˜èª
    - word_type: å“è©ï¼ˆã€Œåè©ã€ã€Œå‹•è©ã€ã€Œå½¢å®¹è©ã€ãªã©ï¼‰
    - frequency: ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…ã§ã®å‡ºç¾å›æ•°
    - created_at: ä½œæˆæ—¥æ™‚
    - updated_at: æ›´æ–°æ—¥æ™‚
    
    Returns:
        bool: å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        st.info("ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆREVIEW_CATEGORIESï¼‰ã®ä½œæˆ
        st.write("ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­...")
        snowflake_session.sql("""
        CREATE TABLE IF NOT EXISTS REVIEW_CATEGORIES (
            category_id NUMBER AUTOINCREMENT,
            category_name VARCHAR(100),
            description TEXT,
            created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
            updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
        )
        """).collect()

        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆREVIEW_TAGSï¼‰ã®ä½œæˆ
        st.write("ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­...")
        snowflake_session.sql("""
        CREATE TABLE IF NOT EXISTS REVIEW_TAGS (
            tag_id NUMBER AUTOINCREMENT,
            review_id VARCHAR(20),
            category_name VARCHAR(100),
            confidence_score FLOAT,
            created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
            updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
        )
        """).collect()
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: é‡è¦å˜èªãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆREVIEW_WORDSï¼‰ã®ä½œæˆ
        st.write("é‡è¦å˜èªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆä¸­...")
        snowflake_session.sql("""
        CREATE TABLE IF NOT EXISTS REVIEW_WORDS (
            word_id NUMBER AUTOINCREMENT,
            review_id VARCHAR(20),
            word VARCHAR(100),
            word_type VARCHAR(50),
            frequency NUMBER,
            created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),
            updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
        )
        """).collect()

        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªã®ç™»éŒ²ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ï¼‰
        st.write("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’ç™»éŒ²ä¸­...")
        categories_values = ", ".join([f"('{category}')" for category in DEFAULT_CATEGORIES])
        
        # ã‚«ãƒ†ã‚´ãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ç™»éŒ²ã™ã‚‹SQL
        insert_result = snowflake_session.sql(f"""
        INSERT INTO REVIEW_CATEGORIES (category_name)
        SELECT category FROM (VALUES {categories_values}) AS v(category)
        WHERE category NOT IN (SELECT category_name FROM REVIEW_CATEGORIES)
        """).collect()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå¾Œã®çŠ¶æ³ã‚’ç¢ºèª
        categories_count = get_table_count("REVIEW_CATEGORIES")
        tags_count = get_table_count("REVIEW_TAGS")
        words_count = get_table_count("REVIEW_WORDS")
        
        st.success(f"""
        ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ:
        - ã‚«ãƒ†ã‚´ãƒª: {categories_count} ä»¶
        - ã‚¿ã‚°: {tags_count} ä»¶
        - å˜èª: {words_count} ä»¶
        """)
            
        return True
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        st.code(str(e))
        return False

def get_review_categories() -> list:
    """
    ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒªã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    REVIEW_CATEGORIESãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ã‚«ãƒ†ã‚´ãƒªåã‚’å–å¾—ã—ã€
    ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¿”ã—ã¾ã™ã€‚
    
    Returns:
        list: ã‚«ãƒ†ã‚´ãƒªåã®ãƒªã‚¹ãƒˆã€‚ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚„
              ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™ã€‚
    
    Example:
        categories = get_review_categories()
        for category in categories:
            print(category)
    """
    try:
        result = snowflake_session.sql("""
            SELECT category_name
            FROM REVIEW_CATEGORIES
            ORDER BY category_name
        """).collect()
        return [row['CATEGORY_NAME'] for row in result]
    except Exception as e:
        st.error(f"ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

def add_review_category(category_name: str, description: str = None) -> bool:
    """
    æ–°ã—ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ ã—ã¾ã™ã€‚
    
    æ—¢ã«åŒåã®ã‚«ãƒ†ã‚´ãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯è¿½åŠ ã•ã‚Œã¾ã›ã‚“ã€‚
    ã‚«ãƒ†ã‚´ãƒªåãŒç©ºæ–‡å­—ã‚„ç„¡åŠ¹ãªå€¤ã®å ´åˆã‚‚ã‚¨ãƒ©ãƒ¼ã¨ãªã‚Šã¾ã™ã€‚
    
    Args:
        category_name (str): ã‚«ãƒ†ã‚´ãƒªå
        description (str, optional): ã‚«ãƒ†ã‚´ãƒªã®èª¬æ˜
    
    Returns:
        bool: è¿½åŠ ã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        snowflake_session.sql("""
            INSERT INTO REVIEW_CATEGORIES (category_name, description)
            SELECT ?, ?
            WHERE NOT EXISTS (
                SELECT 1 FROM REVIEW_CATEGORIES WHERE category_name = ?
            )
        """, params=[category_name, description, category_name]).collect()
        return True
    except Exception as e:
        st.error(f"ã‚«ãƒ†ã‚´ãƒªã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def delete_review_category(category_name: str) -> bool:
    """
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒªã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    
    Args:
        category_name (str): å‰Šé™¤ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªå
    
    Returns:
        bool: å‰Šé™¤ã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        # ã‚«ãƒ†ã‚´ãƒªã®å‰Šé™¤
        snowflake_session.sql("""
            DELETE FROM REVIEW_CATEGORIES
            WHERE category_name = ?
        """, params=[category_name]).collect()
        
        # é–¢é€£ã™ã‚‹ã‚¿ã‚°ã®å‰Šé™¤
        snowflake_session.sql("""
            DELETE FROM REVIEW_TAGS
            WHERE category_name = ?
        """, params=[category_name]).collect()
        
        return True
    except Exception as e:
        st.error(f"ã‚«ãƒ†ã‚´ãƒªã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def generate_review_tags() -> bool:
    """
    æœªåˆ†é¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«å¯¾ã—ã¦ã‚¿ã‚°ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚
    
    ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼š
    1. ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã‚’å–å¾—
    2. ã¾ã ã‚¿ã‚°ä»˜ã‘ã•ã‚Œã¦ã„ãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
    3. CLASSIFY_TEXTé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡
    4. åˆ†é¡çµæœã‚’REVIEW_TAGSãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    
    CLASSIFY_TEXTé–¢æ•°ã¯LLMã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç™»éŒ²æ¸ˆã¿ã®
    ã‚«ãƒ†ã‚´ãƒªã®ã„ãšã‚Œã‹ã«åˆ†é¡ã—ã¾ã™ã€‚ã“ã‚Œã¯ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡ã§ã‚ã‚Šã€
    äº‹å‰ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ä¸è¦ã§ã™ã€‚
    
    Returns:
        bool: ã‚¿ã‚°ç”Ÿæˆå‡¦ç†ã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã®å–å¾—
        categories = get_review_categories()
        if not categories:
            st.warning("ã‚«ãƒ†ã‚´ãƒªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã¯ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            return False
        
        # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’JSONå½¢å¼ã§æº–å‚™
        categories_json = json.dumps(categories, ensure_ascii=False)
        st.write(f"**ç™»éŒ²æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒª**: {', '.join(categories)}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: æœªåˆ†é¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
        reviews = snowflake_session.sql("""
            SELECT r.*
            FROM CUSTOMER_REVIEWS r
            LEFT JOIN REVIEW_TAGS t
            ON r.review_id = t.review_id
            WHERE t.review_id IS NULL
            -- å…¨ä»¶å‡¦ç†ã™ã‚‹ãŸã‚ã«åˆ¶é™ã‚’å‰Šé™¤
        """).collect()
        
        if not reviews:
            st.info("åˆ†é¡ãŒå¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return True
        
        st.write(f"**åˆè¨ˆ {len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†é¡ã—ã¾ã™**")
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        # å‡¦ç†çŠ¶æ³ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹å¤‰æ•°
        processed_count = 0
        success_count = 0
        
        for i, review in enumerate(reviews):
            try:
                # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†é¡
                # CLASSIFY_TEXTé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‰¹å®šã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡
                result = snowflake_session.sql("""
                    SELECT 
                        SNOWFLAKE.CORTEX.CLASSIFY_TEXT(
                            ?,  -- åˆ†é¡ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
                            PARSE_JSON(?),  -- åˆ†é¡ã‚«ãƒ†ã‚´ãƒªã®ãƒªã‚¹ãƒˆ
                            {
                                'task_description': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‹ã‚‰æœ€ã‚‚é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚'
                            }
                        ) as classification
                """, params=[
                    review['REVIEW_TEXT'],
                    categories_json
                ]).collect()[0]['CLASSIFICATION']
                
                # çµæœã‚’JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹
                classification = json.loads(result)
                assigned_category = classification.get('label', 'ãã®ä»–')
                
                # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¿ã‚°æƒ…å ±ã‚’ä¿å­˜
                snowflake_session.sql("""
                    INSERT INTO REVIEW_TAGS (
                        review_id,
                        category_name,
                        confidence_score
                    )
                    VALUES (?, ?, 1.0)
                """, params=[
                    review['REVIEW_ID'],
                    assigned_category
                ]).collect()
                
                success_count += 1
                
            except Exception as e:
                st.error(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ID {review['REVIEW_ID']} ã®åˆ†é¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            processed_count += 1
            
            # é€²æ—çŠ¶æ³ã®æ›´æ–°
            progress = (i + 1) / len(reviews)
            progress_bar.progress(progress)
            progress_text.text(f"å‡¦ç†é€²æ—: {i + 1}/{len(reviews)} ä»¶å®Œäº†ï¼ˆæˆåŠŸ: {success_count}ä»¶ï¼‰")
        
        st.success(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ã‚°ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚{success_count}/{processed_count} ä»¶ã‚’æ­£å¸¸ã«å‡¦ç†ã—ã¾ã—ãŸã€‚")
        return True
    
    except Exception as e:
        st.error(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åˆ†é¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.code(str(e))
        return False

def extract_important_words() -> bool:
    """
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰é‡è¦ãªå˜èªã‚’æŠ½å‡ºã—ã€åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚
    
    ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼š
    1. å˜èªæŠ½å‡ºãŒã¾ã è¡Œã‚ã‚Œã¦ã„ãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
    2. ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’10ä»¶ãšã¤ã®ãƒãƒƒãƒã«åˆ†å‰²
    3. å„ãƒãƒƒãƒå†…ã®è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¸€åº¦ã®COMPLETEé–¢æ•°å‘¼ã³å‡ºã—ã§ã¾ã¨ã‚ã¦å‡¦ç†
    4. å˜èªã®å“è©ã¨å‡ºç¾é »åº¦ã‚’åˆ†æ
    5. çµæœã‚’REVIEW_WORDSãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    
    COMPLETEé–¢æ•°ã¯æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰ã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œã•ã‚Œã€
    ãƒ†ã‚­ã‚¹ãƒˆå†…ã®é‡è¦ãªå˜èªã€ãã®å“è©ã€å‡ºç¾é »åº¦ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€é »å‡ºå˜èªã‚„ç‰¹å¾´çš„ãªè¡¨ç¾ã‚’åˆ†æã§ãã¾ã™ã€‚
    
    æŠ½å‡ºã•ã‚Œã‚‹å“è©:
    - åè©: è£½å“åã€ç‰¹å¾´ã€éƒ¨å“åãªã©
    - å‹•è©: æ“ä½œã‚„å‹•ä½œã‚’è¡¨ã™èª
    - å½¢å®¹è©: è©•ä¾¡ã‚„æ„Ÿæƒ³ã‚’è¡¨ã™èª
    
    Returns:
        bool: å˜èªæŠ½å‡ºå‡¦ç†ã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: æœªå‡¦ç†ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
        reviews = snowflake_session.sql("""
            SELECT r.*
            FROM CUSTOMER_REVIEWS r
            LEFT JOIN REVIEW_WORDS w
            ON r.review_id = w.review_id
            WHERE w.review_id IS NULL
            -- å…¨ä»¶å‡¦ç†ã™ã‚‹ãŸã‚ã«åˆ¶é™ã‚’å‰Šé™¤
        """).collect()
        
        if not reviews:
            st.info("å‡¦ç†ãŒå¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return True
        
        st.write(f"**åˆè¨ˆ {len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰å˜èªã‚’æŠ½å‡ºã—ã¾ã™**")
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        # å‡¦ç†çŠ¶æ³ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹å¤‰æ•°
        processed_count = 0
        words_extracted = 0
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è¨­å®š
        batch_size = 10
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒãƒƒãƒã«åˆ†å‰²
        for i in range(0, len(reviews), batch_size):
            batch = reviews[i:i+batch_size]
            batch_reviews_ids = [review['REVIEW_ID'] for review in batch]
            
            try:
                st.write(f"ãƒãƒƒãƒ {i//batch_size + 1}: {len(batch)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¸€åº¦ã«å‡¦ç†ä¸­...")
                
                # è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™
                combined_reviews = []
                for idx, review in enumerate(batch):
                    combined_reviews.append({
                        "id": review['REVIEW_ID'],
                        "text": review['REVIEW_TEXT']
                    })
                
                # ã‚¹ãƒ†ãƒƒãƒ—2: è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¸€åº¦ã®COMPLETEå‘¼ã³å‡ºã—ã§å‡¦ç†
                result = snowflake_session.sql("""
                    SELECT SNOWFLAKE.CORTEX.COMPLETE(
                        ?,  -- ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
                        [
                            {
                                'role': 'system',
                                'content': 'è¤‡æ•°ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é‡è¦ãªå˜èªã‚’æŠ½å‡ºã—ã€å“è©ã¨å‡ºç¾å›æ•°ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã”ã¨ã«åˆ†æçµæœã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚'
                            },
                            {
                                'role': 'user',
                                'content': ?  -- åˆ†æã™ã‚‹è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆï¼ˆJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
                            }
                        ],
                        {
                            'temperature': 0,  -- ç”Ÿæˆçµæœã®å¤šæ§˜æ€§ï¼ˆ0=æ±ºå®šçš„ãªå‡ºåŠ›ï¼‰
                            'max_tokens': 2000,  -- æœ€å¤§å¿œç­”ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã™
                            'response_format': {
                                'type': 'json',
                                'schema': {
                                    'type': 'object',
                                    'properties': {
                                        'reviews_analysis': {
                                            'type': 'array',
                                            'items': {
                                                'type': 'object',
                                                'properties': {
                                                    'review_id': {
                                                        'type': 'string',
                                                        'description': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ID'
                                                    },
                                                    'words': {
                                                        'type': 'array',
                                                        'items': {
                                                            'type': 'object',
                                                            'properties': {
                                                                'word': {
                                                                    'type': 'string',
                                                                    'description': 'æŠ½å‡ºã•ã‚ŒãŸå˜èª'
                                                                },
                                                                'type': {
                                                                    'type': 'string',
                                                                    'enum': ['åè©', 'å‹•è©', 'å½¢å®¹è©'],
                                                                    'description': 'å“è©ï¼ˆåè©ã€å‹•è©ã€å½¢å®¹è©ã®ã„ãšã‚Œã‹ï¼‰'
                                                                },
                                                                'frequency': {
                                                                    'type': 'integer',
                                                                    'description': 'å˜èªã®å‡ºç¾å›æ•°'
                                                                }
                                                            },
                                                            'required': ['word', 'type', 'frequency']
                                                        }
                                                    }
                                                },
                                                'required': ['review_id', 'words']
                                            }
                                        }
                                    },
                                    'required': ['reviews_analysis']
                                }
                            }
                        }
                    ) as result
                """, params=[
                    complete_model,
                    json.dumps(combined_reviews)  # JSONã¨ã—ã¦è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ¸¡ã™
                ]).collect()[0]['RESULT']
                
                # ã‚¹ãƒ†ãƒƒãƒ—3: çµæœã‚’JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹
                response = json.loads(result)
                
                # Snowflake Cortexã®å‡ºåŠ›å½¢å¼ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®å‡¦ç†
                reviews_data = []
                if 'structured_output' in response:
                    # æ–°å½¢å¼
                    structured_output = response.get('structured_output', [{}])[0].get('raw_message', {})
                    reviews_data = structured_output.get('reviews_analysis', [])
                else:
                    # æ—§å½¢å¼ï¼ˆç›´æ¥JSONï¼‰
                    reviews_data = response.get('reviews_analysis', [])
                
                # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒãƒƒãƒå†…ã®å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å˜èªæƒ…å ±ã‚’å‡¦ç†
                local_processed = 0
                for review_data in reviews_data:
                    review_id = review_data.get('review_id')
                    words_data = review_data.get('words', [])
                    
                    # review_idãŒå®Ÿéš›ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼IDã¨ä¸€è‡´ã—ãªã„å ´åˆã®å¯¾å¿œ
                    # ä¸€è‡´ã—ãªã„å ´åˆã¯ã€ãƒãƒƒãƒå†…ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼IDã‚’é †ç•ªã«å‰²ã‚Šå½“ã¦ã‚‹
                    if not review_id or review_id not in batch_reviews_ids:
                        if local_processed < len(batch):
                            review_id = batch[local_processed]['REVIEW_ID']
                    
                    # å˜èªæƒ…å ±ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
                    local_words_count = 0
                    for word in words_data:
                        # å˜èªãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                        if not all(k in word for k in ['word', 'type', 'frequency']):
                            continue
                            
                        # ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥
                        snowflake_session.sql("""
                            INSERT INTO REVIEW_WORDS (
                                review_id,
                                word,
                                word_type,
                                frequency
                            )
                            VALUES (?, ?, ?, ?)
                        """, params=[
                            review_id,
                            word['word'],
                            word['type'],
                            word['frequency']
                        ]).collect()
                        
                        local_words_count += 1
                    
                    words_extracted += local_words_count
                    local_processed += 1
                
                # ã‚‚ã—AIã®å‡ºåŠ›ãŒä¸å®Œå…¨ã ã£ãŸå ´åˆã€æ®‹ã‚Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚‚å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
                processed_count += len(batch)
                
                # ãƒãƒƒãƒã”ã¨ã®é€²æ—çŠ¶æ³ã®æ›´æ–°
                progress = min(1.0, processed_count / len(reviews))
                progress_bar.progress(progress)
                progress_text.text(f"å‡¦ç†é€²æ—: {processed_count}/{len(reviews)} ä»¶å®Œäº† (åˆè¨ˆ {words_extracted} å˜èªæŠ½å‡ºæ¸ˆã¿)")
                
            except Exception as e:
                st.error(f"ãƒãƒƒãƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚«ã‚¦ãƒ³ãƒˆã‚’é€²ã‚ã‚‹
                processed_count += len(batch)
        
        st.success(f"å˜èªæŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚{processed_count} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰åˆè¨ˆ {words_extracted} å˜èªã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
        return True
    except Exception as e:
        st.error(f"å˜èªæŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.code(str(e))
        return False

# =========================================================
# Cortex Search Service æ“ä½œ
# =========================================================

def check_search_service_exists() -> bool:
    """Cortex Search ServiceãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    
    Returns:
        bool: æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯Trueã€å­˜åœ¨ã—ãªã„å ´åˆã¯False
    """
    try:
        # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        current_db_schema = snowflake_session.sql("SELECT CURRENT_DATABASE(), CURRENT_SCHEMA()").collect()[0]
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã®å­˜åœ¨ç¢ºèª
        result = snowflake_session.sql(f"""
            SHOW CORTEX SEARCH SERVICES LIKE 'snow_retail_search_service'
        """).collect()
        
        return len(result) > 0
    
    except Exception:
        return False  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å­˜åœ¨ã—ãªã„ã¨åˆ¤æ–­

def create_snow_retail_search_service(warehouse, model) -> bool:
    """Cortex Search Serviceã‚’ä½œæˆã—ã¾ã™ã€‚
    
    Args:
        warehouse (str): ä½¿ç”¨ã™ã‚‹Snowflakeã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹å
        model (str): ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
    
    Returns:
        bool: ã‚µãƒ¼ãƒ“ã‚¹ä½œæˆã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        current_db_schema = snowflake_session.sql("SELECT CURRENT_DATABASE(), CURRENT_SCHEMA()").collect()[0]
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã®ä½œæˆ
        try:
            snowflake_session.sql(f"""
            CREATE OR REPLACE CORTEX SEARCH SERVICE snow_retail_search_service
            ON content
            ATTRIBUTES title, document_type, department
            WAREHOUSE = '{warehouse}'
            TARGET_LAG = '1 day'
            EMBEDDING_MODEL = '{model}'
            AS
                SELECT 
                document_id,
                title,
                content,
                document_type,
                department,
                created_at,
                updated_at,
                version
            FROM SNOW_RETAIL_DOCUMENTS
            """).collect()
        except Exception as sql_error:
            # SQLå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚ã€ã‚µãƒ¼ãƒ“ã‚¹ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¢ºèª
            if check_search_service_exists():
                st.success("Cortex Search Serviceã¯æ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚")
                
                # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ä»˜ä¸
                snowflake_session.sql(f"""
                    GRANT USAGE ON CORTEX SEARCH SERVICE snow_retail_search_service TO ROLE CURRENT_ROLE()
                """).collect()
                
                return True
            else:
                # æœ¬å½“ã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸå ´åˆ
                raise sql_error
        
        # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ä»˜ä¸
        snowflake_session.sql(f"""
            GRANT USAGE ON CORTEX SEARCH SERVICE snow_retail_search_service TO ROLE CURRENT_ROLE()
        """).collect()
        
        st.success("Cortex Search Serviceã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
        return True
    
    except Exception as e:
        # ã‚µãƒ¼ãƒ“ã‚¹ä½œæˆä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¦ã‚‚ã†ä¸€åº¦å­˜åœ¨ç¢ºèª
        if check_search_service_exists():
            st.success("Cortex Search Serviceã¯æ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚")
            return True
        
        st.error(f"Cortex Search Serviceã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def delete_snow_retail_search_service() -> bool:
    """ã‚¹ãƒãƒ¼ãƒªãƒ†ãƒ¼ãƒ«ã®Cortex Search Serviceã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    
    Returns:
        bool: å‰Šé™¤ã«æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯False
    """
    try:
        # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
        current_db_schema = snowflake_session.sql("SELECT CURRENT_DATABASE(), CURRENT_SCHEMA()").collect()[0]
        current_database = current_db_schema['CURRENT_DATABASE()']
        current_schema = current_db_schema['CURRENT_SCHEMA()']
        
        snowflake_session.sql(f"""
            DROP CORTEX SEARCH SERVICE {current_database}.{current_schema}.snow_retail_search_service
        """).collect()
        st.success("Cortex Search Serviceã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        return True
    except Exception as e:
        st.error(f"Cortex Search Serviceã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

# =========================================================
# UIé–¢æ•°
# =========================================================

def render_data_preparation_page():
    """ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.header("ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™æ©Ÿèƒ½ã®æ¦‚è¦èª¬æ˜
    st.info("""
    ## ğŸ” ãƒ‡ãƒ¼ã‚¿æº–å‚™æ©Ÿèƒ½ã«ã¤ã„ã¦
    
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†ææº–å‚™ã‚’è¡Œã„ã¾ã™ã€‚ä»¥ä¸‹ã®å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ï¼š
    
    ### 1. ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã¨åˆæœŸè¨­å®š
    * åˆ†æç”¨ãƒ†ãƒ¼ãƒ–ãƒ« (CUSTOMER_ANALYSIS) ã®ä½œæˆ
    
    ### 2. ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
    * **ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²**: SPLIT_TEXT_RECURSIVE_CHARACTERé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’300æ–‡å­—ä»¥å†…ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    * **ç¿»è¨³å‡¦ç†**: TRANSLATEé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã«ç¿»è¨³
    * **æ„Ÿæƒ…åˆ†æ**: SENTIMENTé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ (-1ã€œ1) ã‚’ç®—å‡º
    * **ãƒ™ã‚¯ãƒˆãƒ«åŒ–**: EMBED_TEXT_1024é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’1024æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    """)
    
    # åˆ†æç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆã‚’ä¿ƒã™
    if not check_table_exists("CUSTOMER_ANALYSIS"):
        st.warning("åˆ†æç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã¾ãšã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        if st.button("åˆ†æç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"):
            if create_customer_analysis_table():
                st.success("åˆ†æç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                st.rerun()
        return
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒœã‚¿ãƒ³
    if st.button("ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã‚’å®Ÿè¡Œ"):
        with st.expander("å‡¦ç†ã®è©³ç´°", expanded=True):
            st.info("ä»¥ä¸‹ã®å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ï¼š\n"
                   "1. æœªå‡¦ç†ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—\n"
                   "2. ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰² (SPLIT_TEXT_RECURSIVE_CHARACTERé–¢æ•°)\n"
                   "3. æ„Ÿæƒ…åˆ†æã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œ (TRANSRATEé–¢æ•°ã€SENTIMENTé–¢æ•°ã€EMBED_TEXT_1024é–¢æ•°)\n"
                   "4. åˆ†æçµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ« (CUSTOMER_ANALYSIS) ã«ä¿å­˜")
            process_review_chunks()
    
    # ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿çŠ¶æ³")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("### åº—èˆ—ãƒ‡ãƒ¼ã‚¿")
        retail_count = get_table_count("RETAIL_DATA_WITH_PRODUCT_MASTER")
        st.metric("åº—èˆ—ãƒ‡ãƒ¼ã‚¿æ•°", retail_count)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        if retail_count > 0:
            with st.expander("åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«"):
                sample = snowflake_session.sql("""
                    SELECT 
                        transaction_id, 
                        product_id_master, 
                        product_name_master, 
                        transaction_date, 
                        quantity 
                    FROM RETAIL_DATA_WITH_PRODUCT_MASTER 
                    LIMIT 3
                """).collect()
                for item in sample:
                    st.write(f"**ID**: {item['TRANSACTION_ID']}, **å•†å“**: {item['PRODUCT_NAME_MASTER']}")
                    st.write(f"**æ—¥ä»˜**: {item['TRANSACTION_DATE']}, **æ•°é‡**: {item['QUANTITY']}")
                    st.write("---")
    
    with col2:
        st.info("### ECãƒ‡ãƒ¼ã‚¿")
        ec_count = get_table_count("EC_DATA_WITH_PRODUCT_MASTER")
        st.metric("ECãƒ‡ãƒ¼ã‚¿æ•°", ec_count)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        if ec_count > 0:
            with st.expander("ECãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«"):
                sample = snowflake_session.sql("""
                    SELECT 
                        transaction_id, 
                        product_id_master, 
                        product_name_master, 
                        transaction_date, 
                        quantity 
                    FROM EC_DATA_WITH_PRODUCT_MASTER 
                    LIMIT 3
                """).collect()
                for item in sample:
                    st.write(f"**ID**: {item['TRANSACTION_ID']}, **å•†å“**: {item['PRODUCT_NAME_MASTER']}")
                    st.write(f"**æ—¥ä»˜**: {item['TRANSACTION_DATE']}, **æ•°é‡**: {item['QUANTITY']}")
                    st.write("---")
    
    with col3:
        st.info("### ç¤¾å†…æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿")
        document_count = get_table_count("SNOW_RETAIL_DOCUMENTS")
        st.metric("æ–‡æ›¸ç·æ•°", document_count)
        
        # æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒ
        if document_count > 0:
            with st.expander("æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒ"):
                doc_types = snowflake_session.sql("""
                    SELECT document_type, COUNT(*) as count
                    FROM SNOW_RETAIL_DOCUMENTS
                    GROUP BY document_type
                    ORDER BY count DESC
                """).collect()
                for dt in doc_types:
                    st.write(f"**{dt['DOCUMENT_TYPE']}**: {dt['COUNT']} ä»¶")
                    
        st.info("### å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
        analysis_count = get_table_count("CUSTOMER_ANALYSIS")
        st.metric("å‡¦ç†æ¸ˆã¿ãƒãƒ£ãƒ³ã‚¯æ•°", analysis_count)
        
        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ
        if analysis_count > 0:
            with st.expander("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ"):
                sentiment_stats = snowflake_session.sql("""
                    SELECT 
                        MIN(sentiment_score) as min_score,
                        MAX(sentiment_score) as max_score,
                        AVG(sentiment_score) as avg_score
                    FROM CUSTOMER_ANALYSIS
                """).collect()[0]
                st.write(f"**æœ€å°ã‚¹ã‚³ã‚¢**: {sentiment_stats['MIN_SCORE']:.2f}")
                st.write(f"**æœ€å¤§ã‚¹ã‚³ã‚¢**: {sentiment_stats['MAX_SCORE']:.2f}")
                st.write(f"**å¹³å‡ã‚¹ã‚³ã‚¢**: {sentiment_stats['AVG_SCORE']:.2f}")

def render_voice_analysis_page():
    """é¡§å®¢ã®å£°åˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.header("é¡§å®¢ã®å£°åˆ†æ")
    
    # å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆã‚’ä¿ƒã™
    if not check_table_exists("REVIEW_CATEGORIES") or not check_table_exists("REVIEW_TAGS"):
        st.warning("ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã¾ãšã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        if st.button("ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"):
            if create_review_management_tables():
                st.success("ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                st.rerun()
        return
    
    # åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "âš™ï¸ ç®¡ç†",
        "ğŸ“Š å…¨ä½“æ¦‚è¦",
        "ğŸ˜Š æ„Ÿæƒ…åˆ†æ",
        "ğŸ”¤ å˜èªåˆ†æ",
        "ğŸ“ è©³ç´°åˆ†æ",
        "ğŸ” é¡§å®¢ã®å£°æ¤œç´¢"
    ])
    
    with tab1:
        render_management_page()
    
    with tab2:
        render_overview_dashboard()
    
    with tab3:
        render_sentiment_analysis()
    
    with tab4:
        render_word_analysis()
    
    with tab5:
        render_detail_analysis()
    
    with tab6:
        render_vector_search()

def render_overview_dashboard():
    """å…¨ä½“æ¦‚è¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã«å¤‰æ›´ã—ã¦è¦–è¦šçš„éšå±¤ã‚’æ•´ç†
    st.subheader("å…¨ä½“æ¦‚è¦")
    
    # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    df = pd.DataFrame(snowflake_session.sql("""
        WITH review_stats AS (
            SELECT 
                r.review_id,
                r.rating,
                r.review_text,
                r.helpful_votes,
                t.category_name,
                a.sentiment_score,
                DATE_TRUNC('month', r.review_date) as review_month
            FROM CUSTOMER_REVIEWS r
            LEFT JOIN REVIEW_TAGS t ON r.review_id = t.review_id
            LEFT JOIN CUSTOMER_ANALYSIS a ON r.review_id = a.review_id
        )
        SELECT * FROM review_stats
    """).collect())
    
    if df.empty:
        st.info("åˆ†æå¯èƒ½ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ä¸Šéƒ¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", len(df))
    with col2:
        st.metric("å¹³å‡è©•ä¾¡", f"{df['RATING'].mean():.1f}")
    with col3:
        st.metric("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{df['SENTIMENT_SCORE'].mean():.2f}")
    with col4:
        st.metric("ç·å‚è€ƒã«ãªã£ãŸæ•°", df['HELPFUL_VOTES'].sum())
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒªã‚¢
    col1, col2 = st.columns(2)
    
    with col1:
        # è©•ä¾¡åˆ†å¸ƒ
        fig_rating = px.histogram(
            df,
            x="RATING",
            title="è©•ä¾¡åˆ†å¸ƒ",
            labels={"RATING": "è©•ä¾¡", "count": "ä»¶æ•°"},
            nbins=10
        )
        st.plotly_chart(fig_rating, use_container_width=True, key="overview_rating_hist")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°
        if 'CATEGORY_NAME' in df.columns:
            fig_category = px.bar(
                df["CATEGORY_NAME"].value_counts().reset_index(),
                x="CATEGORY_NAME",
                y="count",
                title="ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°",
                labels={"CATEGORY_NAME": "ã‚«ãƒ†ã‚´ãƒª", "count": "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°"}
            )
            fig_category.update_layout(xaxis_tickangle=45)
            st.plotly_chart(fig_category, use_container_width=True, key="overview_category_bar")
    
    with col2:
        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
        fig_sentiment = px.histogram(
            df,
            x="SENTIMENT_SCORE",
            title="æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
            labels={"SENTIMENT_SCORE": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", "count": "ä»¶æ•°"},
            nbins=20
        )
        st.plotly_chart(fig_sentiment, use_container_width=True, key="overview_sentiment_hist")
        
        # æœˆåˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°æ¨ç§»
        monthly_reviews = df.groupby("REVIEW_MONTH").size().reset_index(name="count")
        fig_trend = px.line(
            monthly_reviews,
            x="REVIEW_MONTH",
            y="count",
            title="æœˆåˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°æ¨ç§»",
            labels={"REVIEW_MONTH": "æœˆ", "count": "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°"}
        )
        st.plotly_chart(fig_trend, use_container_width=True, key="overview_monthly_trend")

def render_sentiment_analysis():
    """æ„Ÿæƒ…åˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    
    # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    df = pd.DataFrame(snowflake_session.sql("""
        SELECT 
            r.review_id,
            r.rating,
            r.review_text,
            r.helpful_votes,
            t.category_name,
            a.sentiment_score,
            TO_VARCHAR(DATE_TRUNC('month', r.review_date)) as review_month
        FROM CUSTOMER_REVIEWS r
        LEFT JOIN REVIEW_TAGS t ON r.review_id = t.review_id
        LEFT JOIN (
            SELECT review_id, MIN(sentiment_score) as sentiment_score
            FROM CUSTOMER_ANALYSIS
            GROUP BY review_id
        ) a ON r.review_id = a.review_id
        WHERE a.sentiment_score IS NOT NULL
    """).collect())
    
    if df.empty:
        st.info("æ„Ÿæƒ…åˆ†æãŒå®Œäº†ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if 'CATEGORY_NAME' in df.columns and not df['CATEGORY_NAME'].isna().all():
        categories = [cat for cat in df["CATEGORY_NAME"].unique() if cat is not None]
        selected_categories = st.multiselect(
            "ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
            categories,
            default=categories
        )
        filtered_df = df[df["CATEGORY_NAME"].isin(selected_categories)]
    else:
        filtered_df = df
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨è©•ä¾¡ã®ç›¸é–¢ï¼ˆé‡è¦ãªæ„Ÿæƒ…åˆ†æå›ºæœ‰ã®å†…å®¹ï¼‰
    st.subheader("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†æ")
    if 'CATEGORY_NAME' in filtered_df.columns and not filtered_df['CATEGORY_NAME'].isna().all():
        col1, col2 = st.columns(2)
        
        with col1:
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢
            category_sentiment = filtered_df.groupby("CATEGORY_NAME")["SENTIMENT_SCORE"].mean().reset_index()
            fig_category_sentiment = px.bar(
                category_sentiment,
                x="CATEGORY_NAME",
                y="SENTIMENT_SCORE",
                title="ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢",
                labels={"CATEGORY_NAME": "ã‚«ãƒ†ã‚´ãƒª", "SENTIMENT_SCORE": "å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢"}
            )
            fig_category_sentiment.update_layout(xaxis_tickangle=45)
            st.plotly_chart(fig_category_sentiment, use_container_width=True, key="sentiment_category_score_bar")
        
        with col2:
            # è©•ä¾¡ã¨æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®ç›¸é–¢
            fig_correlation = px.scatter(
                filtered_df,
                x="RATING",
                y="SENTIMENT_SCORE",
                color="CATEGORY_NAME",
                title="è©•ä¾¡ã¨æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®ç›¸é–¢",
                labels={
                    "RATING": "è©•ä¾¡",
                    "SENTIMENT_SCORE": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢",
                    "CATEGORY_NAME": "ã‚«ãƒ†ã‚´ãƒª"
                }
            )
            st.plotly_chart(fig_correlation, use_container_width=True, key="sentiment_correlation_scatter")
    
    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®é«˜ã„/ä½ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤º
    st.subheader("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("#### æœ€ã‚‚è‚¯å®šçš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼")
        positive_reviews = filtered_df.nlargest(5, "SENTIMENT_SCORE")
        for _, review in positive_reviews.iterrows():
            with st.expander(f"æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {review['SENTIMENT_SCORE']:.2f}"):
                st.write(review["REVIEW_TEXT"])
    
    with col2:
        st.write("#### æœ€ã‚‚å¦å®šçš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼")
        negative_reviews = filtered_df.nsmallest(5, "SENTIMENT_SCORE")
        for _, review in negative_reviews.iterrows():
            with st.expander(f"æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {review['SENTIMENT_SCORE']:.2f}"):
                st.write(review["REVIEW_TEXT"])

def render_word_analysis():
    """å˜èªåˆ†æãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å˜èªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    if not check_table_exists("REVIEW_WORDS"):
        st.warning("é‡è¦å˜èªãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã¾ãšã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã€å˜èªæŠ½å‡ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã®å–å¾—
    categories = get_review_categories()
    if not categories:
        st.warning("ã‚«ãƒ†ã‚´ãƒªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    selected_category = st.selectbox(
        "ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        ["ã™ã¹ã¦"] + categories
    )
    
    # å˜èªã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    word_types = snowflake_session.sql("""
        SELECT DISTINCT word_type FROM REVIEW_WORDS
        ORDER BY word_type
    """).collect()
    word_types = [row['WORD_TYPE'] for row in word_types]
    selected_word_types = st.multiselect(
        "å˜èªã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        word_types,
        default=word_types
    )
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã®æ§‹ç¯‰
    category_condition = f"t.category_name = '{selected_category}'" if selected_category != "ã™ã¹ã¦" else "1=1"
    word_type_condition = "w.word_type IN (" + ", ".join([f"'{wt}'" for wt in selected_word_types]) + ")" if selected_word_types else "1=1"
    
    # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    df = pd.DataFrame(snowflake_session.sql(f"""
        WITH product_data AS (
            -- åº—èˆ—ãƒ‡ãƒ¼ã‚¿
            SELECT 
                r.product_id_master as product_id,
                r.product_name_master
            FROM RETAIL_DATA_WITH_PRODUCT_MASTER r
            
            UNION ALL
            
            -- ECãƒ‡ãƒ¼ã‚¿
            SELECT 
                e.product_id_master as product_id,
                e.product_name_master
            FROM EC_DATA_WITH_PRODUCT_MASTER e
        ),
        -- æ­£ç¢ºãªå˜èªå‡ºç¾å›æ•°ã‚’è¨ˆç®—
        word_frequency AS (
            SELECT 
                word,
                word_type,
                COUNT(DISTINCT review_id) as review_count,
                -- å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã®å®Ÿéš›ã®å‡ºç¾å›æ•°ã‚’åˆè¨ˆ
                SUM(frequency) as actual_total
            FROM (
                -- å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§å„å˜èªã¯1å›ã ã‘ã‚«ã‚¦ãƒ³ãƒˆï¼ˆé‡è¤‡ã‚’æ’é™¤ï¼‰
                SELECT 
                    word,
                    word_type,
                    review_id,
                    frequency
                FROM REVIEW_WORDS
                QUALIFY ROW_NUMBER() OVER (PARTITION BY word, word_type, review_id ORDER BY frequency DESC) = 1
            )
            GROUP BY word, word_type
        )
        
        SELECT 
            w.word,
            w.word_type,
            w.review_count,
            -- ç·å‡ºç¾å›æ•°ã¯å˜èªã®å…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã®å‡ºç¾å›æ•°
            ROUND(w.actual_total) as total_mentions,
            -- å¹³å‡å‡ºç¾å›æ•°ã¯ç·å‡ºç¾å›æ•°ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã§å‰²ã£ãŸå€¤
            ROUND(w.actual_total / w.review_count, 2) as avg_frequency,
            LISTAGG(DISTINCT p.product_name_master, ', ') WITHIN GROUP (ORDER BY p.product_name_master) as products
        FROM word_frequency w
        LEFT JOIN REVIEW_WORDS rw ON w.word = rw.word AND w.word_type = rw.word_type
        LEFT JOIN REVIEW_TAGS t ON rw.review_id = t.review_id
        LEFT JOIN CUSTOMER_ANALYSIS a ON rw.review_id = a.review_id
        LEFT JOIN product_data p ON p.product_id = a.product_id
        WHERE {category_condition} AND {word_type_condition}
        AND w.review_count > 1
        GROUP BY w.word, w.word_type, w.review_count, w.actual_total
        ORDER BY total_mentions DESC
        LIMIT 100
    """).collect())
    
    if df.empty:
        st.info("æ¡ä»¶ã«åˆã†å˜èªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # å˜èªã®å‡ºç¾çŠ¶æ³ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã§è¡¨ç¤º
    st.subheader("å˜èªå‡ºç¾çŠ¶æ³")
    
    # åˆ—ã®è¡¨ç¤ºå½¢å¼ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    formatted_df = df.copy()
    
    def format_product_list(product_text):
        """å•†å“ãƒªã‚¹ãƒˆã‚’æ•´å½¢ã™ã‚‹é–¢æ•°"""
        if product_text is None or product_text == '':
            return 'é–¢é€£å•†å“ãªã—'
        
        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
        if len(product_text) > 100:
            return product_text[:100] + '...'
        return product_text
    
    # å•†å“ãƒªã‚¹ãƒˆã®æ•´å½¢
    formatted_df['PRODUCTS'] = formatted_df['PRODUCTS'].apply(format_product_list)
    
    # å‡ºç¾å›æ•°ã®èª¬æ˜æ–‡ã‚’è¿½åŠ 
    st.info("""
    â€» å‡ºç¾ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦:
    - ã€Œãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã€: ã“ã®å˜èªãŒå‡ºç¾ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ä»¶æ•°ã§ã™
    - ã€Œç·å‡ºç¾å›æ•°ã€: ã™ã¹ã¦ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…ã§ã®ã“ã®å˜èªã®åˆè¨ˆå‡ºç¾å›æ•°ã§ã™ (å„ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…ã§ã®å‡ºç¾å›æ•°ã®åˆè¨ˆ)
    - ã€Œå¹³å‡å‡ºç¾å›æ•°ã€: 1ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚ãŸã‚Šã®å¹³å‡å‡ºç¾å›æ•°ã§ã™
    """)
    
    st.dataframe(
        formatted_df.rename(columns={
            "WORD": "å˜èª",
            "WORD_TYPE": "å“è©",
            "REVIEW_COUNT": "ãƒ‡ãƒ¼ã‚¿ä»¶æ•°",
            "TOTAL_MENTIONS": "ç·å‡ºç¾å›æ•°",
            "AVG_FREQUENCY": "å¹³å‡å‡ºç¾å›æ•°",
            "PRODUCTS": "é–¢é€£å•†å“"
        }),
        use_container_width=True
    )
    
    # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã®è¡¨ç¤º
    st.subheader("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
    # ã“ã“ã§ã¯å˜ç´”ãªé »åº¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
    # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã†ã“ã¨ã‚‚å¯èƒ½ã ãŒä»Šå›ã¯ç°¡ç•¥åŒ–
    
    col1, col2 = st.columns(2)
    
    with col1:
        words_by_type = df.groupby('WORD_TYPE')['TOTAL_MENTIONS'].sum().reset_index()
        fig = px.pie(
            words_by_type,
            values='TOTAL_MENTIONS',
            names='WORD_TYPE',
            title='å“è©åˆ¥ã®å˜èªå‡ºç¾å›æ•°ã®å‰²åˆ'
        )
        st.plotly_chart(fig, use_container_width=True, key="word_analysis_pie")
    
    with col2:
        top_words = df.head(20)
        fig = px.bar(
            top_words,
            x='WORD',
            y='TOTAL_MENTIONS',
            title='ç·å‡ºç¾å›æ•°TOP20ã®å˜èª',
            labels={"WORD": "å˜èª", "TOTAL_MENTIONS": "ç·å‡ºç¾å›æ•°"}
        )
        fig.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig, use_container_width=True, key="word_analysis_top20")

def render_detail_analysis():
    """è©³ç´°åˆ†æï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    
    categories = get_review_categories()
    if not categories:
        st.info("ã‚«ãƒ†ã‚´ãƒªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    selected_category = st.selectbox(
        "åˆ†æã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
        categories
    )
    
    # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤º
    reviews = snowflake_session.sql("""
        SELECT 
            r.*,
            t.confidence_score,
            a.sentiment_score
        FROM REVIEW_TAGS t
        JOIN CUSTOMER_REVIEWS r ON t.review_id = r.review_id
        LEFT JOIN (
            SELECT review_id, MIN(sentiment_score) as sentiment_score
            FROM CUSTOMER_ANALYSIS
            GROUP BY review_id
        ) a ON r.review_id = a.review_id
        WHERE t.category_name = ?
        ORDER BY r.review_date DESC
    """, params=[selected_category]).collect()
    
    if reviews:
        for review in reviews:
            with st.expander(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼: {review['REVIEW_TEXT'][:100]}..."):
                st.write(f"**æ„Ÿæƒ…ã‚¹ã‚³ã‚¢**: {review['SENTIMENT_SCORE']:.2f}")
                st.write(f"**è©•ä¾¡**: {review['RATING']}")
                st.write(f"**æŠ•ç¨¿æ—¥**: {review['REVIEW_DATE']}")
                st.write(f"**å‚è€ƒã«ãªã£ãŸæ•°**: {review['HELPFUL_VOTES']}")
    else:
        st.info(f"ã‚«ãƒ†ã‚´ãƒª '{selected_category}' ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

def render_analyst_chatbot_page():
    """Cortex Analystã‚’ä½¿ç”¨ã—ãŸåˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.header("åˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—å‘ã‘ã®èª¬æ˜
    st.info("""
    ## ğŸ“Š åˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã¤ã„ã¦
    
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€Snowflake Cortex Analystã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½“é¨“ã§ãã¾ã™ã€‚
    
    ### ä¸»ãªæ©Ÿèƒ½
    * **è‡ªç„¶è¨€èªã§ã®ãƒ‡ãƒ¼ã‚¿åˆ†æ**: è³ªå•ã‚’SQLã«è‡ªå‹•å¤‰æ›ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã—ã¦å®Ÿè¡Œ
    * **è¦–è¦šåŒ–**: åˆ†æçµæœã‚’è‡ªå‹•çš„ã«ã‚°ãƒ©ãƒ•åŒ–ã—ã¦è¡¨ç¤º
    * **æ—¥æœ¬èªå¯¾å¿œ**: è‹±èªã§è¿”ã•ã‚Œã‚‹åˆ†æçµæœã‚’è‡ªå‹•çš„ã«æ—¥æœ¬èªã«ç¿»è¨³
    
    ### ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ
    * ä»Šå›ã¯åº—èˆ—ã¨ECã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ã„ã‚‹ãŸã‚ã€è²©å£²æ•°é‡ã‚„å£²ä¸Šé‡‘é¡ãªã©ã®åˆ†æã«é©ã—ã¦ã„ã¾ã™ã€‚
    * ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è³ªå•ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œ2023å¹´ã®å››åŠæœŸã”ã¨ã®å£²ä¸Šæ¨ç§»ã‚’æ•™ãˆã¦ã€ï¼‰
    * è³ªå•ã¯ãƒ‡ãƒ¼ã‚¿ã«é–¢é€£ã™ã‚‹ã‚‚ã®ã«é™å®šã•ã‚Œã¾ã™ï¼ˆä¸€èˆ¬çš„ãªä¼šè©±ã§ã¯ãªãã€ãƒ‡ãƒ¼ã‚¿åˆ†æã®ã‚¯ã‚¨ãƒªã¨ã—ã¦è§£é‡ˆã•ã‚Œã¾ã™ï¼‰
    * åˆ†æçµæœã¯ã‚°ãƒ©ãƒ•ã¨è¡¨å½¢å¼ã§è¡¨ç¤ºã•ã‚Œã€ç”Ÿæˆã•ã‚ŒãŸSQLã‚‚ç¢ºèªã§ãã¾ã™
    
    ### ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«
    ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ã€é¸æŠã—ãŸã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç†è§£ã—ã¦ã„ã¾ã™ã€‚
    """)
    
    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
    semantic_model_files = get_semantic_model_files()
    
    if not semantic_model_files:
        st.error(f"""
        ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚
        ã‚¹ãƒ†ãƒ¼ã‚¸ 'SEMANTIC_MODEL_STAGE' ã«ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.yamlã¾ãŸã¯.ymlï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
        """)
        return
    
    SEMANTIC_MODEL_STAGE = "SEMANTIC_MODEL_STAGE"
    selected_model_file = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        semantic_model_files,
        index=0
    )
    
    # é¸æŠã•ã‚ŒãŸã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
    full_stage_path = f"@{SEMANTIC_MODEL_STAGE}/{selected_model_file}"
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "analyst_messages" not in st.session_state:
        st.session_state.analyst_messages = []
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.analyst_messages = []
        st.rerun()
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.analyst_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "result" in message and message["result"] is not None:
                # çµæœãŒ DataFrame ã§ã‚ã‚Œã°è¡¨ç¤º
                if isinstance(message["result"], pd.DataFrame) and not message["result"].empty:
                    st.dataframe(message["result"])
                
                # SQLã‚¯ã‚¨ãƒªãŒå«ã¾ã‚Œã¦ã„ã‚Œã°è¡¨ç¤º
                if "sql" in message and message["sql"]:
                    with st.expander("ç”Ÿæˆã•ã‚ŒãŸSQL"):
                        st.code(message["sql"], language="sql")
                
                # ã‚°ãƒ©ãƒ•ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°è¡¨ç¤º
                if "chart" in message and message["chart"]:
                    st.plotly_chart(message["chart"], use_container_width=True, key=f"analyst_chart_{st.session_state.analyst_messages.index(message)}")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç†
    if prompt := st.chat_input("ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        st.session_state.analyst_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # å›ç­”ç”Ÿæˆã®å‡¦ç†
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æº–å‚™
                messages = [
                    {
                        "role": "user",
                        "content": [{"type": "text", "text": prompt}]
                    }
                ]
                
                # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®æº–å‚™
                request_body = {
                    "messages": messages,
                    "semantic_model_file": full_stage_path,
                }
                
                # Cortex Analyst APIå‘¼ã³å‡ºã—
                try:
                    import _snowflake
                    # Snowflakeå†…éƒ¨APIã‚’ä½¿ç”¨
                    resp = _snowflake.send_snow_api_request(
                        "POST",
                        ANALYST_API_ENDPOINT,
                        {},  # headers
                        {},  # params
                        request_body,
                        None,  # request_guid
                        ANALYST_API_TIMEOUT * 1000,  # ãƒŸãƒªç§’ã«å¤‰æ›
                    )
                    
                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
                    if resp["status"] < 400:
                        response_data = json.loads(resp["content"])
                        if "message" in response_data and "content" in response_data["message"]:
                            content_list = response_data["message"]["content"]
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆã¨SQLã‚’æŠ½å‡º
                            response_text = ""
                            sql_query = ""
                            result_data = None
                            chart = None
                            
                            for item in content_list:
                                if item["type"] == "text":
                                    response_text += item["text"] + "\n\n"
                                elif item["type"] == "sql":
                                    sql_query = item["statement"]
                            
                            # è‹±èªã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ—¥æœ¬èªã«ç¿»è¨³
                            if response_text:
                                try:
                                    translated_response = snowflake_session.sql("""
                                        SELECT SNOWFLAKE.CORTEX.TRANSLATE(?, 'en', 'ja') as translated
                                    """, params=[response_text.strip()]).collect()[0]['TRANSLATED']
                                    response_text = translated_response
                                except Exception as translate_error:
                                    st.warning(f"ç¿»è¨³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å…ƒã®è‹±èªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤ºã—ã¾ã™: {str(translate_error)}")
                            
                            # SQLã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                            try:
                                # SQLã‚¯ã‚¨ãƒªãŒå­˜åœ¨ã—ã€ç©ºã§ãªã„å ´åˆã®ã¿å®Ÿè¡Œ
                                if sql_query and sql_query.strip():
                                    result_data = snowflake_session.sql(sql_query).to_pandas()
                                else:
                                    # SQLãŒç”Ÿæˆã•ã‚Œãªã‹ã£ãŸå ´åˆ
                                    result_data = None
                                    chart = None
                                
                                # ã‚·ãƒ³ãƒ—ãƒ«ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ï¼‰
                                if result_data is not None and not result_data.empty and len(result_data.columns) >= 2:
                                    x_col = result_data.columns[0]
                                    y_col = result_data.columns[1]
                                    
                                    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚°ãƒ©ãƒ•ã‚’é¸æŠ
                                    if result_data[x_col].dtype == 'object':  # ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿
                                        chart = px.bar(
                                            result_data,
                                            x=x_col,
                                            y=y_col,
                                            title="åˆ†æçµæœ"
                                        )
                                    else:  # æ•°å€¤ãƒ‡ãƒ¼ã‚¿
                                        chart = px.line(
                                            result_data,
                                            x=x_col,
                                            y=y_col,
                                            title="åˆ†æçµæœ"
                                        )
                            except Exception as sql_error:
                                st.error(f"SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(sql_error)}")
                                result_data = None
                                chart = None
                            
                            # å¿œç­”ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
                            st.session_state.analyst_messages.append({
                                "role": "assistant", 
                                "content": response_text.strip(),
                                "result": result_data,
                                "sql": sql_query,
                                "chart": chart
                            })
                            
                            # å¿œç­”ã‚’è¡¨ç¤º
                            with st.chat_message("assistant"):
                                st.markdown(response_text.strip())
                                
                                if result_data is not None and not result_data.empty:
                                    st.dataframe(result_data)
                                
                                if chart:
                                    st.plotly_chart(chart, use_container_width=True)
                                
                                if sql_query:
                                    with st.expander("ç”Ÿæˆã•ã‚ŒãŸSQL"):
                                        st.code(sql_query, language="sql")
                        else:
                            raise Exception("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å½¢å¼ãŒä¸æ­£ã§ã™")
                    else:
                        error_content = json.loads(resp["content"])
                        error_msg = f"""
                        ğŸš¨ APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ğŸš¨
                        
                        * ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: `{resp['status']}`
                        * ãƒªã‚¯ã‚¨ã‚¹ãƒˆID: `{error_content.get('request_id', 'N/A')}`
                        * ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: `{error_content.get('error_code', 'N/A')}`
                        
                        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
                        ```
                        {error_content.get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}
                        ```
                        """
                        raise Exception(error_msg)
                
                except ImportError:
                    # Snowflakeå†…éƒ¨APIãŒä½¿ç”¨ã§ããªã„å ´åˆ
                    st.error("Snowflakeã®å†…éƒ¨APIã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚Streamlit in Snowflakeç’°å¢ƒã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    
                    # ä»£æ›¿ã®ãƒ¢ãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
                    response_text = f"è³ªå•: {prompt}\n\nç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€Cortex Analystã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æœ¬æ¥ã§ã‚ã‚Œã°ã€ã“ã“ã«ãƒ‡ãƒ¼ã‚¿åˆ†æã®çµæœãŒæ—¥æœ¬èªã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
                    result_data = pd.DataFrame({
                        "ã‚«ãƒ†ã‚´ãƒª": ["å•†å“ã®å“è³ª", "ä¾¡æ ¼", "æ¥å®¢ã‚µãƒ¼ãƒ“ã‚¹", "åº—èˆ—ç’°å¢ƒ", "ãã®ä»–"],
                        "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°": [45, 32, 28, 15, 10]
                    })
                    
                    # ãƒ¢ãƒƒã‚¯ãƒãƒ£ãƒ¼ãƒˆ
                    chart = px.bar(
                        result_data,
                        x="ã‚«ãƒ†ã‚´ãƒª",
                        y="ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°",
                        title="ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰"
                    )
                    
                    # å¿œç­”ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
                    st.session_state.analyst_messages.append({
                        "role": "assistant", 
                        "content": response_text,
                        "result": result_data,
                        "sql": "-- ãƒ¢ãƒƒã‚¯SQL\nSELECT category_name, COUNT(*) as count\nFROM REVIEW_TAGS\nGROUP BY category_name\nORDER BY count DESC",
                        "chart": chart
                    })
                    
                    # å¿œç­”ã‚’è¡¨ç¤º
                    with st.chat_message("assistant"):
                        st.markdown(response_text)
                        st.dataframe(result_data)
                        st.plotly_chart(chart, use_container_width=True)
                        
                        with st.expander("ãƒ¢ãƒƒã‚¯SQL"):
                            st.code("-- ãƒ¢ãƒƒã‚¯SQL\nSELECT category_name, COUNT(*) as count\nFROM REVIEW_TAGS\nGROUP BY category_name\nORDER BY count DESC", language="sql")
                
            except Exception as e:
                error_msg = f"""
                Cortex Analystã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚
                ã‚¨ãƒ©ãƒ¼: {str(e)}
                
                **ç¢ºèªäº‹é …:**
                1. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{selected_model_file}' ãŒã‚¹ãƒ†ãƒ¼ã‚¸ '{SEMANTIC_MODEL_STAGE}' ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
                2. Cortex Analystã‚µãƒ¼ãƒ“ã‚¹ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
                3. å¿…è¦ãªæ¨©é™ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
                
                **ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹:** {full_stage_path}
                """
                
                st.error(error_msg)
                st.code(str(e))
                
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
                st.session_state.analyst_messages.append({
                    "role": "assistant", 
                    "content": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    "result": None
                })

def render_management_page():
    """ç®¡ç†ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    # ã‚¿ãƒ–ã®å†…å®¹ãªã®ã§ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ä¸è¦
    
    st.info("""
    ## ğŸ›  é¡§å®¢ã®å£°åˆ†æã«ã¤ã„ã¦
    
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ãŸã‚ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    
    ã¾ãšã¯ã‚¿ã‚°ã®ä¸€æ‹¬ç”Ÿæˆã¨å˜èªã®æŠ½å‡ºã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚
    """)
    
    # ã‚«ãƒ†ã‚´ãƒªã®ç®¡ç†
    render_category_management()
    
    st.markdown("---")
    
    # ã‚¿ã‚°ã®ä¸€æ‹¬ç”Ÿæˆ
    st.subheader("ã‚¿ã‚°ã®ä¸€æ‹¬ç”Ÿæˆ")
    st.info("""
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•çš„ã«åˆ†æã—ã€å†…å®¹ã«åŸºã¥ã„ã¦ã‚«ãƒ†ã‚´ãƒªã‚’è¨­å®šã—ã¾ã™ã€‚
    
    **ä½¿ç”¨AIæ©Ÿèƒ½**: `CLASSIFY_TEXTé–¢æ•°`
    
    ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ã€CLASSIFY_TEXTé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å†…å®¹ã‚’åˆ†æã—ã€äº‹å‰ã«å®šç¾©ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚‚ã®ã‚’è¨­å®šã—ã¾ã™ã€‚
    
    å‡¦ç†çµæœã¯REVIEW_TAGSãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
    """)
    if st.button("ã‚¿ã‚°ã‚’ä¸€æ‹¬ç”Ÿæˆ", key="page_generate_tags"):
        with st.expander("å‡¦ç†ã®è©³ç´°", expanded=True):
            st.info("å‡¦ç†ä¸­ã¯ã“ã¡ã‚‰ã«é€²æ—çŠ¶æ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            generate_review_tags()
    
    st.markdown("---")
    
    # å˜èªã®æŠ½å‡º
    st.subheader("å˜èªã®æŠ½å‡º")
    st.info("""
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é‡è¦ãªå˜èªã‚’æŠ½å‡ºã—ã€ãã®å“è©ã‚„å‡ºç¾é »åº¦ã‚’åˆ†æã—ã¾ã™ã€‚
    
    **ä½¿ç”¨AIæ©Ÿèƒ½**: `COMPLETEé–¢æ•°ã®æ§‹é€ åŒ–å‡ºåŠ›æ©Ÿèƒ½`
    
    ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ã€COMPLETEé–¢æ•°ã®æ§‹é€ åŒ–å‡ºåŠ›æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰é‡è¦ãªå˜èª (åè©ã€å‹•è©ã€å½¢å®¹è©) ã‚’æŠ½å‡ºã—ã€
    ãã‚Œãã‚Œã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚æŠ½å‡ºã•ã‚ŒãŸå˜èªã¯ã€Œå˜èªåˆ†æã€ã‚¿ãƒ–ã§ç¢ºèªã§ãã¾ã™ã€‚
    
    **å‡¦ç†å†…å®¹**:
    1. æœªå‡¦ç†ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    2. 10ä»¶ãšã¤ã®ãƒãƒƒãƒã§å‡¦ç†ã‚’å®Ÿè¡Œ (COMPLETEé–¢æ•°ã®æ§‹é€ åŒ–å‡ºåŠ›æ©Ÿèƒ½)
    3. é‡è¦å˜èªã®æŠ½å‡ºã¨ãã®å“è©ã®åˆ¤å®š
    4. å˜èªã®å‡ºç¾å›æ•°ã®é›†è¨ˆ
    5. çµæœã‚’REVIEW_WORDSãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    """)
    if st.button("å˜èªã‚’æŠ½å‡º", key="page_extract_words"):
        with st.expander("å‡¦ç†ã®è©³ç´°", expanded=True):
            st.info("å‡¦ç†ä¸­ã¯ã“ã¡ã‚‰ã«é€²æ—çŠ¶æ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            extract_important_words()

def render_category_management():
    """ã‚«ãƒ†ã‚´ãƒªç®¡ç†æ©Ÿèƒ½ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.subheader("ã‚«ãƒ†ã‚´ãƒªã®ç®¡ç†")
    
    st.info("""
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã®ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆãƒ»ç®¡ç†ã—ã¾ã™ã€‚ã‚«ãƒ†ã‚´ãƒªã¯ã‚¿ã‚°ç”Ÿæˆæ™‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("#### ç¾åœ¨ã®ã‚«ãƒ†ã‚´ãƒªä¸€è¦§")
        categories = get_review_categories()
        if categories:
            selected = st.selectbox(
                "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                categories,
                key="category_select"
            )
            if st.button("é¸æŠã—ãŸã‚«ãƒ†ã‚´ãƒªã‚’å‰Šé™¤", key="delete_category"):
                if delete_review_category(selected):
                    st.success(f"ã‚«ãƒ†ã‚´ãƒª '{selected}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                    st.rerun()
        else:
            st.info("ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    with col2:
        st.write("#### æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã®è¿½åŠ ")
        with st.form("add_category_form", clear_on_submit=True):
            new_category = st.text_input("ã‚«ãƒ†ã‚´ãƒªå", key="new_category_name")
            description = st.text_area("èª¬æ˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰", key="new_category_desc")
            submitted = st.form_submit_button("è¿½åŠ ")
            if submitted and new_category:
                if add_review_category(new_category, description):
                    st.success(f"ã‚«ãƒ†ã‚´ãƒª '{new_category}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
                    st.rerun()

def render_vector_search():
    """é¡§å®¢ã®å£°æ¤œç´¢æ©Ÿèƒ½ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"""
    # ã™ã§ã«ã‚¿ãƒ–ãŒã‚¿ã‚¤ãƒˆãƒ«ã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã€ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ä¸è¦
    
    with st.expander("ğŸ” ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        ### ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä»•çµ„ã¿
        
        ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯**ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢**ã‚’ä½¿ã£ã¦ã€é¡§å®¢ã®å£°ã‚’æ›–æ˜§æ¤œç´¢ã§ãã¾ã™ã€‚
        
        **ä»•çµ„ã¿**:
        1. æ¤œç´¢æ–‡å­—åˆ—ã‚’ãƒ™ã‚¯ãƒˆãƒ« (1024æ¬¡å…ƒã®æ•°å€¤é…åˆ—) ã«å¤‰æ›
        2. å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã¨ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
        3. é¡ä¼¼åº¦ã®é«˜ã„é †ã«çµæœã‚’è¡¨ç¤º
        
        ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã¯ã€2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«é–“ã®è§’åº¦ã®ã‚³ã‚µã‚¤ãƒ³ã‚’æ¸¬å®šã—ã€
        [-1, 1]ã®ç¯„å›²ã§é¡ä¼¼åº¦ã‚’è¿”ã—ã¾ã™ã€‚å€¤ãŒ1ã«è¿‘ã„ã»ã©ã€ã‚ˆã‚Šé¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
        
        **ç‰¹é•·**:
        - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å®Œå…¨ä¸€è‡´ã ã‘ã§ãªãã€æ„å‘³çš„ã«é–¢é€£ã™ã‚‹å†…å®¹ã‚‚æ¤œç´¢å¯èƒ½
        - é¡ç¾©èªã‚„é–¢é€£æ¦‚å¿µã‚‚æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹
        """)
    
    # æ¤œç´¢UI
    st.write("### æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›")
    
    # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã®å…¥åŠ›
        search_query = st.text_input(
            "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", 
            placeholder="ä¾‹: ã€Œå•†å“ã®å“è³ªã«ã¤ã„ã¦ä¸æº€ã€ã€Œé…é€ãŒæ—©ãã¦æº€è¶³ã€ãªã©"
        )
    
    with col2:
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
        top_k = st.slider("è¡¨ç¤ºä»¶æ•°", min_value=1, max_value=20, value=5)
        min_score = st.slider("æœ€å°é¡ä¼¼åº¦", min_value=0.0, max_value=1.0, value=0.2, step=0.05)
    
    # æ¤œç´¢ãƒœã‚¿ãƒ³
    search_button = st.button("æ¤œç´¢", type="primary", use_container_width=True)
    
    # æ¤œç´¢å®Ÿè¡Œ
    if search_query and search_button:
        # å‡¦ç†ä¸­è¡¨ç¤º
        with st.spinner("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œä¸­..."):
            try:
                # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®å®Ÿè¡Œï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ä½¿ç”¨ï¼‰
                # CTE (Common Table Expression) ã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¸€æ™‚çš„ã«ä¿å­˜ã—ã€
                search_results = snowflake_session.sql(f"""
                    WITH query_embedding AS (
                        SELECT SNOWFLAKE.CORTEX.EMBED_TEXT_1024('{embedding_model}', ?) AS vector
                    )
                    SELECT 
                        ca.review_id,
                        r.product_id,
                        r.rating,
                        r.review_text,
                        r.review_date,
                        r.purchase_channel,
                        r.helpful_votes,
                        ca.chunked_text,
                        ca.sentiment_score,
                        t.category_name,
                        VECTOR_COSINE_SIMILARITY(ca.embedding, (SELECT vector FROM query_embedding)) as similarity_score
                    FROM CUSTOMER_ANALYSIS ca
                    JOIN CUSTOMER_REVIEWS r ON ca.review_id = r.review_id
                    LEFT JOIN REVIEW_TAGS t ON r.review_id = t.review_id
                    WHERE ca.embedding IS NOT NULL
                    AND VECTOR_COSINE_SIMILARITY(ca.embedding, (SELECT vector FROM query_embedding)) >= ?
                    ORDER BY similarity_score DESC
                    LIMIT ?
                """, params=[search_query, min_score, top_k]).collect()
                
                # æ¤œç´¢çµæœã®è¡¨ç¤º
                if search_results:
                    st.success(f"æ¤œç´¢çµæœ: {len(search_results)}ä»¶")
                    
                    # çµæœã®æ¦‚è¦
                    avg_similarity = sum(r['SIMILARITY_SCORE'] for r in search_results) / len(search_results)
                    st.info(f"å¹³å‡é¡ä¼¼åº¦: {avg_similarity:.2f}")
                    
                    # ã‚¿ãƒ–ã§å„çµæœã‚’è¡¨ç¤º
                    tabs = st.tabs([f"çµæœ {i+1} ({r['SIMILARITY_SCORE']:.2f})" for i, r in enumerate(search_results)])
                    
                    for i, (tab, result) in enumerate(zip(tabs, search_results)):
                        with tab:
                            similarity = result['SIMILARITY_SCORE']
                            
                            # ã‚«ãƒ¼ãƒ‰å½¢å¼ã§çµæœã‚’è¡¨ç¤º
                            col1, col2 = st.columns([3, 1])
                            
                            with col1:
                                # ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹
                                st.markdown(f"#### ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                                st.markdown(f"{result['REVIEW_TEXT']}")
                            
                            with col2:
                                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                                st.metric("é¡ä¼¼åº¦", f"{similarity:.2f}")
                                st.metric("è©•ä¾¡", f"{result['RATING']}")
                                st.metric("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{result['SENTIMENT_SCORE']:.2f}")
                            
                            # è©³ç´°æƒ…å ±
                            st.markdown("#### è©³ç´°æƒ…å ±")
                            st.markdown(f"""
                            | é …ç›® | å†…å®¹ |
                            | --- | --- |
                            | **ãƒ¬ãƒ“ãƒ¥ãƒ¼ID** | {result['REVIEW_ID']} |
                            | **ã‚«ãƒ†ã‚´ãƒª** | {result['CATEGORY_NAME'] or 'æœªåˆ†é¡'} |
                            | **æŠ•ç¨¿æ—¥** | {result['REVIEW_DATE']} |
                            | **è³¼å…¥ãƒãƒ£ãƒãƒ«** | {result['PURCHASE_CHANNEL']} |
                            | **å‚è€ƒã«ãªã£ãŸæ•°** | {result['HELPFUL_VOTES']} |
                            """)
                else:
                    st.warning(f"""
                    æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼š
                    - åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã™ã‚‹
                    - ã‚ˆã‚Šä¸€èˆ¬çš„ãªè¡¨ç¾ã‚’ä½¿ã†
                    - æœ€å°é¡ä¼¼åº¦ã®ã—ãã„å€¤ã‚’ä¸‹ã’ã‚‹ï¼ˆç¾åœ¨: {min_score}ï¼‰
                    """)
                    
            except Exception as e:
                st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.code(str(e))
    elif not search_query and search_button:
        st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    # ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ï¼ˆæ¤œç´¢å®Ÿè¡Œå‰ã®ã¿è¡¨ç¤ºï¼‰
    if not search_query or not search_button:
        st.markdown("""
        ### ä½¿ã„æ–¹
        1. æ¤œç´¢ã—ãŸã„å†…å®¹ã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
        2. å¿…è¦ã«å¿œã˜ã¦è¡¨ç¤ºä»¶æ•°ã‚„æœ€å°é¡ä¼¼åº¦ã‚’èª¿æ•´
        3. ã€Œæ¤œç´¢ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦çµæœã‚’è¡¨ç¤º
        
        #### æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ
        - **è‡ªç„¶æ–‡ã§å…¥åŠ›**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã ã‘ã§ãªãã€æ–‡ç« ã§å…¥åŠ›ã™ã‚‹ã¨é–¢é€£æ€§ã®é«˜ã„çµæœãŒå¾—ã‚‰ã‚Œã‚„ã™ã„ã§ã™
        - **å…·ä½“çš„ã«**: ã€Œå“è³ªã€ã‚ˆã‚Šã‚‚ã€Œå•†å“ã®è€ä¹…æ€§ã«ã¤ã„ã¦ã€ã®ã‚ˆã†ã«å…·ä½“çš„ã«æ›¸ãã¨è‰¯ã„çµæœãŒå¾—ã‚‰ã‚Œã¾ã™
        - **å¦å®šè¡¨ç¾ã‚‚æœ‰åŠ¹**: ã€Œã€œã«ã¤ã„ã¦ä¸æº€ã€ã®ã‚ˆã†ã«å¦å®šçš„ãªå†…å®¹ã‚‚æ¤œç´¢ã§ãã¾ã™
        """)

def render_simple_chatbot_page():
    """ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.header("ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—å‘ã‘ã®èª¬æ˜
    st.info("""
    ## ğŸ¤– ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã¤ã„ã¦
    
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€Snowflake Cortexã®ç”ŸæˆAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸåŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½“é¨“ã§ãã¾ã™ã€‚
    
    ### ä¸»ãªæ©Ÿèƒ½
    * **ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ**: COMPLETEé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ãŸå¿œç­”ã‚’ç”Ÿæˆ
    * **ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ä¿æŒ**: ä¼šè©±ã®æ–‡è„ˆã‚’ä¿æŒã—ã€ã‚ˆã‚Šè‡ªç„¶ãªå¯¾è©±ã‚’å®Ÿç¾
    
    ### ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ
    * è³ªå•ã‚„æŒ‡ç¤ºã‚’è‡ªç„¶ãªæ–‡ç« ã§å…¥åŠ›ã—ã¦ãã ã•ã„
    * è¤‡é›‘ãªè³ªå•ã®å ´åˆã¯ã€å…·ä½“çš„ã«è©³ç´°ã‚’è¨˜è¿°ã™ã‚‹ã¨ã‚ˆã‚Šè‰¯ã„å¿œç­”ãŒå¾—ã‚‰ã‚Œã¾ã™
    * ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã›ãšã€ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã ã‘ã§å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™
    """)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.chat_history = ""
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.session_state.chat_history = ""
        st.rerun()
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç†
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤ºã¨å±¥æ­´ã®æ›´æ–°
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.chat_history += f"User: {prompt}\n"
        with st.chat_message("user"):
            st.markdown(prompt)
        
        try:
            # Cortex Completeã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            full_prompt = st.session_state.chat_history + "AI: "
            response = CompleteText(complete_model, full_prompt)
            
            # å¿œç­”ã®è¡¨ç¤ºã¨å±¥æ­´ã®æ›´æ–°
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.session_state.chat_history += f"AI: {response}\n"
            with st.chat_message("assistant"):
                st.markdown(response)
            
        except Exception as e:
            st.error(f"å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def render_rag_chatbot_page():
    """RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"""
    st.header("RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—å‘ã‘ã®èª¬æ˜
    st.info("""
    ## ğŸ“š RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã¤ã„ã¦
    
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€Cortex Searchã‚’ç”¨ã„ãŸRetrieval-Augmented Generation (RAG) ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®é«˜åº¦ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½“é¨“ã§ãã¾ã™ã€‚
    
    ### ä¸»ãªæ©Ÿèƒ½
    * **å¤šè¨€èªå¯¾å¿œ**: Cortex Searchã¯æ—¥æœ¬èªã‚’å«ã‚€è¤‡æ•°ã®è¨€èªã«å¯¾å¿œã—ã¦ã„ã‚‹ãŸã‚ã€è‡ªç„¶ãªæ—¥æœ¬èªã§ã®è³ªå•ãŒå¯èƒ½
    * **æ¤œç´¢å¯¾è±¡ã®è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥æ©Ÿèƒ½**: Cortex Searchã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å®šæœŸçš„ã«æœ€æ–°åŒ–
    * **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨æ›–æ˜§æ¤œç´¢ã®ä¸¡æ–¹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã™ã‚‹ã“ã¨ãŒå¯èƒ½
    
    ### ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ
    * ç¤¾å†…æ–‡æ›¸ã«é–¢ã™ã‚‹è³ªå•ã‚„ã€è£½å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã«é–¢ã™ã‚‹å…·ä½“çš„ãªè³ªå•ã‚’æ—¥æœ¬èªã§å°‹ã­ã¦ã¿ã¦ãã ã•ã„
    * è³ªå•ãŒå…·ä½“çš„ã§ã‚ã‚‹ã»ã©ã€ã‚ˆã‚Šé–¢é€£æ€§ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ¤œç´¢ã•ã‚Œã¾ã™
    * å‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å±•é–‹ã™ã‚‹ã¨ã€å¿œç­”ã®ç”Ÿæˆã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªã§ãã¾ã™
    
    ### æ³¨æ„äº‹é …
    Cortex Search Serviceã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›´æ–°ã«ä¼´ã†ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚³ã‚¹ãƒˆä»¥å¤–ã«ã‚‚ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦ã®æ–™é‡‘ã‚‚ç™ºç”Ÿã—ã¾ã™ã€‚é•·æœŸé–“ä½¿ç”¨ã—ãªã„å ´åˆã¯Cortex Search Serviceã‚’å‰Šé™¤ã™ã‚‹ãªã©ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚
    """)
    
    # Snowflake Root ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
    root = Root(snowflake_session)
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
    current_db_schema = snowflake_session.sql("SELECT CURRENT_DATABASE(), CURRENT_SCHEMA()").collect()[0]
    current_database = current_db_schema['CURRENT_DATABASE()']
    current_schema = current_db_schema['CURRENT_SCHEMA()']
    
    # éƒ¨ç½²ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®å–å¾—
    try:
        departments = snowflake_session.sql("""
            SELECT DISTINCT department FROM snow_retail_documents
            ORDER BY department
        """).collect()
        department_list = [row['DEPARTMENT'] for row in departments]
        
        document_types = snowflake_session.sql("""
            SELECT DISTINCT document_type FROM snow_retail_documents
            ORDER BY document_type
        """).collect()
        document_type_list = [row['DOCUMENT_TYPE'] for row in document_types]
    except Exception as e:
        st.warning("éƒ¨ç½²ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        department_list = []
        document_type_list = []
    
    # Cortex Search Serviceã®ç®¡ç†
    st.subheader("Cortex Search Serviceã®ç®¡ç†")
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã®å­˜åœ¨ç¢ºèª
    service_exists = check_search_service_exists()
    
    if service_exists:
        st.success("Cortex Search ServiceãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
        if st.button("Cortex Search Serviceã‚’å‰Šé™¤"):
            if delete_snow_retail_search_service():
                st.rerun()
    else:
        st.error("Cortex Search ServiceãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã®æº–å‚™ã‚¹ãƒ†ãƒƒãƒ—ã§Cortex Search ServiceãŒæ­£ã—ãä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.info("Cortex Search Serviceã¯ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã®å‰æ®µéšã§ä½œæˆã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        return
    
    st.markdown("---")
    
    # æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¨­å®š
    with st.expander("æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            selected_departments = st.multiselect(
                "éƒ¨ç½²ã§çµã‚Šè¾¼ã¿",
                options=department_list,
                default=[]
            )
        
        with col2:
            selected_document_types = st.multiselect(
                "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã§çµã‚Šè¾¼ã¿",
                options=document_type_list,
                default=[]
            )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "rag_messages" not in st.session_state:
        st.session_state.rag_messages = []
        st.session_state.rag_chat_history = ""
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.rag_messages = []
        st.session_state.rag_chat_history = ""
        st.rerun()
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.rag_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "relevant_docs" in message:
                with st.expander("å‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"):
                    for doc in message["relevant_docs"]:
                        st.markdown(f"""
                        **ã‚¿ã‚¤ãƒˆãƒ«**: {doc['title']}  
                        **ç¨®é¡**: {doc['document_type']}  
                        **éƒ¨ç½²**: {doc['department']}  
                        **å†…å®¹**: {doc['content'][:200]}...
                        """)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç†
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤ºã¨å±¥æ­´ã®æ›´æ–°
        st.session_state.rag_messages.append({"role": "user", "content": prompt})
        st.session_state.rag_chat_history += f"User: {prompt}\n"
        with st.chat_message("user"):
            st.markdown(prompt)
        
        try:
            # Cortex Search Serviceã®å–å¾—
            search_service = (
                root.databases[current_database]
                .schemas[current_schema]
                .cortex_search_services["snow_retail_search_service"]
            )
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®æ§‹ç¯‰
            filter_conditions = []
            
            # éƒ¨ç½²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¿½åŠ 
            if selected_departments:
                dept_conditions = []
                for dept in selected_departments:
                    dept_conditions.append({"@eq": {"department": dept}})
                
                if len(dept_conditions) == 1:
                    filter_conditions.append(dept_conditions[0])
                else:
                    filter_conditions.append({"@or": dept_conditions})
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¿½åŠ 
            if selected_document_types:
                type_conditions = []
                for doc_type in selected_document_types:
                    type_conditions.append({"@eq": {"document_type": doc_type}})
                
                if len(type_conditions) == 1:
                    filter_conditions.append(type_conditions[0])
                else:
                    filter_conditions.append({"@or": type_conditions})
            
            # æœ€çµ‚çš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®çµ„ã¿ç«‹ã¦
            search_filter = None
            if filter_conditions:
                if len(filter_conditions) == 1:
                    search_filter = filter_conditions[0]
                else:
                    search_filter = {"@and": filter_conditions}
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã®è¡¨ç¤º
            if selected_departments or selected_document_types:
                filter_info = []
                if selected_departments:
                    filter_info.append(f"éƒ¨ç½²: {', '.join(selected_departments)}")
                if selected_document_types:
                    filter_info.append(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—: {', '.join(selected_document_types)}")
                st.info(f"ä»¥ä¸‹ã®æ¡ä»¶ã§æ¤œç´¢ã—ã¾ã™: {' / '.join(filter_info)}")
            
            # æ¤œç´¢ã®å®Ÿè¡Œ
            search_args = {
                "query": prompt,
                "columns": ["title", "content", "document_type", "department"],
                "limit": 3
            }
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if search_filter:
                search_args["filter"] = search_filter
            
            search_results = search_service.search(**search_args)
            
            # æ¤œç´¢çµæœã®å–å¾—
            relevant_docs = [
                {
                    "title": result["title"],
                    "content": result["content"],
                    "document_type": result["document_type"],
                    "department": result["department"]
                }
                for result in search_results.results
            ]
            
            # æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨
            context = "å‚è€ƒæ–‡æ›¸:\n"
            for doc in relevant_docs:
                context += f"""
                ã‚¿ã‚¤ãƒˆãƒ«: {doc['title']}
                ç¨®é¡: {doc['document_type']}
                éƒ¨ç½²: {doc['department']}
                å†…å®¹: {doc['content']}
                ---
                """
            
            # COMPLETEã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
            prompt_template = f"""
            ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒªãƒ†ãƒ¼ãƒ«ã®ç¤¾å†…ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            ä»¥ä¸‹ã®æ–‡è„ˆã‚’å‚è€ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
            ã‚ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ­£ç›´ã«ä¼ãˆã¦ãã ã•ã„ã€‚

            æ–‡è„ˆ:
            {context}

            è³ªå•: {prompt}
            """
            
            response = CompleteText(complete_model, prompt_template)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’è¡¨ç¤º
            with st.chat_message("assistant"):
                st.markdown(response)
                with st.expander("å‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"):
                    for doc in relevant_docs:
                        st.markdown(f"""
                        **ã‚¿ã‚¤ãƒˆãƒ«**: {doc['title']}  
                        **ç¨®é¡**: {doc['document_type']}  
                        **éƒ¨ç½²**: {doc['department']}  
                        **å†…å®¹**: {doc['content'][:200]}...
                        """)
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
            st.session_state.rag_messages.append({
                "role": "assistant",
                "content": response,
                "relevant_docs": relevant_docs
            })
            st.session_state.rag_chat_history += f"AI: {response}\n"
            
        except Exception as e:
            st.error(f"å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.code(str(e))

def get_semantic_model_files() -> list:
    """ã‚¹ãƒ†ãƒ¼ã‚¸å†…ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚
    
    Returns:
        list: ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆï¼ˆå–å¾—å¤±æ•—æ™‚ã¯ç©ºãƒªã‚¹ãƒˆï¼‰
    """
    try:
        SEMANTIC_MODEL_STAGE = "SEMANTIC_MODEL_STAGE"
        stage_files = snowflake_session.sql(f"""
            LIST @{SEMANTIC_MODEL_STAGE}
        """).collect()
        
        # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        yaml_files = []
        for file in stage_files:
            filename = file['name']
            # ã‚¹ãƒ†ãƒ¼ã‚¸åãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯å‰Šé™¤
            if '/' in filename:
                filename = filename.split('/')[-1]
            
            if filename.endswith('.yaml') or filename.endswith('.yml'):
                yaml_files.append(filename)
        
        return yaml_files
    except Exception as e:
        st.error(f"ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

# =========================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================================================

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®æ©Ÿèƒ½é¸æŠ
st.sidebar.title("æ©Ÿèƒ½é¸æŠ")
selected_function = st.sidebar.radio(
    "æ©Ÿèƒ½ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["ãƒ‡ãƒ¼ã‚¿æº–å‚™", "é¡§å®¢ã®å£°åˆ†æ", "ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", "RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", "åˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ"]
)

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
st.sidebar.title("ãƒ¢ãƒ‡ãƒ«è¨­å®š")

# ãƒ¢ãƒ‡ãƒ«é¸æŠUI
embedding_model = st.sidebar.selectbox(
    "Embeddingãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    EMBEDDING_MODELS,
    index=0
)

complete_model = st.sidebar.selectbox(
    "Completeãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    COMPLETE_MODELS,
    index=0
)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
st.title("ğŸª ã‚¹ãƒãƒ¼ãƒªãƒ†ãƒ¼ãƒ« é¡§å®¢ã®å£°åˆ†æã‚¢ãƒ—ãƒª")
st.markdown("---")

# é¸æŠã•ã‚ŒãŸæ©Ÿèƒ½ã«å¿œã˜ãŸå‡¦ç†
if selected_function == "ãƒ‡ãƒ¼ã‚¿æº–å‚™":
    render_data_preparation_page()
elif selected_function == "é¡§å®¢ã®å£°åˆ†æ":
    render_voice_analysis_page()
elif selected_function == "ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ":
    render_simple_chatbot_page()
elif selected_function == "RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ":
    render_rag_chatbot_page()
elif selected_function == "åˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ":
    render_analyst_chatbot_page() 